{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53016766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "436ab806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job title</th>\n",
       "      <th>job requirements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Development Manager</td>\n",
       "      <td>['role', 'cooperation', 'manage', 'director', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Video and Motion Graphics Editor</td>\n",
       "      <td>['join', 'organisation', 'difference', 'perfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Programming Assistant - Casual</td>\n",
       "      <td>['office', 'base', 'opportunity', 'gain', 'exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QMC Duty Manager</td>\n",
       "      <td>['amaze', 'organization', 'commit', 'community...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Training Coordinator</td>\n",
       "      <td>['opportunity', 'support', 'audio', 'language'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>Kitchen &amp; Bath Cabinet Sales and Design</td>\n",
       "      <td>['seek', 'design', 'sale', 'consultant', 'show...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>Art Teacher - Trix Academy</td>\n",
       "      <td>['art', 'teacher', 'scholar', 'deserve', 'qual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>CAMPUS ADJUNCT FACULTY- Foundations</td>\n",
       "      <td>['faculty', 'foundation', 'campus', 'draw', 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>K-8 Art Teacher</td>\n",
       "      <td>['school', 'school', 'network', 'charter', 'sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>Quality Control Inspector</td>\n",
       "      <td>['mission', 'quality', 'control', 'technician'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2354 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    job title  \\\n",
       "0                Business Development Manager   \n",
       "1            Video and Motion Graphics Editor   \n",
       "2              Programming Assistant - Casual   \n",
       "3                            QMC Duty Manager   \n",
       "4                        Training Coordinator   \n",
       "...                                       ...   \n",
       "2349  Kitchen & Bath Cabinet Sales and Design   \n",
       "2350               Art Teacher - Trix Academy   \n",
       "2351      CAMPUS ADJUNCT FACULTY- Foundations   \n",
       "2352                          K-8 Art Teacher   \n",
       "2353                Quality Control Inspector   \n",
       "\n",
       "                                       job requirements  \n",
       "0     ['role', 'cooperation', 'manage', 'director', ...  \n",
       "1     ['join', 'organisation', 'difference', 'perfor...  \n",
       "2     ['office', 'base', 'opportunity', 'gain', 'exp...  \n",
       "3     ['amaze', 'organization', 'commit', 'community...  \n",
       "4     ['opportunity', 'support', 'audio', 'language'...  \n",
       "...                                                 ...  \n",
       "2349  ['seek', 'design', 'sale', 'consultant', 'show...  \n",
       "2350  ['art', 'teacher', 'scholar', 'deserve', 'qual...  \n",
       "2351  ['faculty', 'foundation', 'campus', 'draw', 'c...  \n",
       "2352  ['school', 'school', 'network', 'charter', 'sc...  \n",
       "2353  ['mission', 'quality', 'control', 'technician'...  \n",
       "\n",
       "[2354 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentences = data[\"description\"]\n",
    "df = pd.read_csv(\"../data_pre/job data_pre(ver2).csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "537b7d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = df['job requirements']\n",
    "sentences = []\n",
    "for i in range(len(content)):\n",
    "    a = content[i]\n",
    "    a = a.replace(\",\",\" \")\n",
    "    a = a.replace(\"'\",\"\")\n",
    "    a = a.replace(\"[\",\"\")\n",
    "    a = a.replace(\"]\",\"\")\n",
    "    sentences.append(a)\n",
    "#sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5fae4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(norm = None)\n",
    "X = vectorizer.fit_transform(sentences)\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8147ba1c",
   "metadata": {},
   "source": [
    "# Ordering all words by tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58376ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2354, 11159)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caochuxue/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6685</th>\n",
       "      <td>museum</td>\n",
       "      <td>9659.387612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>art</td>\n",
       "      <td>9437.041329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3886</th>\n",
       "      <td>experience</td>\n",
       "      <td>6706.650944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>design</td>\n",
       "      <td>6292.532551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9670</th>\n",
       "      <td>student</td>\n",
       "      <td>5409.217064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>interfacesability</td>\n",
       "      <td>8.071149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5313</th>\n",
       "      <td>interesse</td>\n",
       "      <td>8.071149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>interdisciplines</td>\n",
       "      <td>8.071149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>interdependent</td>\n",
       "      <td>8.071149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11158</th>\n",
       "      <td>ߧߧ</td>\n",
       "      <td>8.071149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11159 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    word        tfidf\n",
       "6685              museum  9659.387612\n",
       "833                  art  9437.041329\n",
       "3886          experience  6706.650944\n",
       "2984              design  6292.532551\n",
       "9670             student  5409.217064\n",
       "...                  ...          ...\n",
       "5315   interfacesability     8.071149\n",
       "5313           interesse     8.071149\n",
       "5312    interdisciplines     8.071149\n",
       "5310      interdependent     8.071149\n",
       "11158                 ߧߧ     8.071149\n",
       "\n",
       "[11159 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(vectorizer.vocabulary_)\n",
    "#print(vectorizer.get_feature_names())\n",
    "#print(X)\n",
    "print(X.shape)\n",
    "word = {\"word\":vectorizer.get_feature_names(), 'tfidf':X.toarray().sum(axis=0).tolist()}\n",
    "word = pd.DataFrame(word)\n",
    "word.sort_values(by='tfidf',ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1c8140",
   "metadata": {},
   "source": [
    "# words and tfidf for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5f536f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'account': 3.4609910983914425, 'range': 2.7530288320463567, 'oversight': 5.026626388167149, 'culture': 2.8921782169751022, 'team': 3.3651748406898863, 'director': 2.719290692414506, 'manage': 2.429241754952459, 'cooperation': 5.719773568727095, 'role': 2.307526350878355}\n",
      "{'opportunity': 2.057433669847771, 'progression': 5.153378093806293, 'career': 2.929485269387913, 'benefit': 2.4653467595945755, 'employee': 2.567851878655998, 'perform': 2.9928548833205024, 'difference': 4.045797135155423, 'organisation': 4.010705815344154, 'join': 2.917857231392794, 'team': 1.6825874203449431}\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary to store the word/key and tfidf/value\n",
    "dict_of_tokens = {i[1]:i[0] for i in vectorizer.vocabulary_.items()}\n",
    "tfidf_vectors = []\n",
    "for row in X:\n",
    "    tfidf_vectors.append({dict_of_tokens[column]:value for (column,value) in zip(row.indices,row.data)})\n",
    "\n",
    "\n",
    "#words for document 0\n",
    "print(tfidf_vectors[0])\n",
    "#words for document 1\n",
    "print(tfidf_vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5277a75",
   "metadata": {},
   "source": [
    "# Select the first 10 words as keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24907c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_vectors = []\n",
    "for i in range(len(tfidf_vectors)):\n",
    "    document_i = tfidf_vectors[i]\n",
    "    if len(document_i) <= 30:    #保留整个document的words\n",
    "        keyword_vectors.append(document_i) \n",
    "    else:\n",
    "        a = sorted(document_i.items(), key=lambda document_i: document_i[1], reverse=True)\n",
    "        for j in range(len(a)-1,9,-1):  #从后往前删除\n",
    "            #if a[j][1] != a[9][1]:\n",
    "                a.pop(j)\n",
    "        keyword_vectors.append(dict(a)) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05421ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'account': 3.4609910983914425, 'range': 2.7530288320463567, 'oversight': 5.026626388167149, 'culture': 2.8921782169751022, 'team': 3.3651748406898863, 'director': 2.719290692414506, 'manage': 2.429241754952459, 'cooperation': 5.719773568727095, 'role': 2.307526350878355}\n",
      "{'opportunity': 2.057433669847771, 'progression': 5.153378093806293, 'career': 2.929485269387913, 'benefit': 2.4653467595945755, 'employee': 2.567851878655998, 'perform': 2.9928548833205024, 'difference': 4.045797135155423, 'organisation': 4.010705815344154, 'join': 2.917857231392794, 'team': 1.6825874203449431}\n"
     ]
    }
   ],
   "source": [
    "#key words for document 0\n",
    "print(keyword_vectors[0])\n",
    "\n",
    "\n",
    "#key words for document 1\n",
    "print(keyword_vectors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2ce60b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pd.DataFrame(keyword_vectors[0].keys())\n",
    "\n",
    "\n",
    "for i in range(1,len(keyword_vectors)):\n",
    "    df_b = pd.DataFrame(keyword_vectors[i].keys())\n",
    "    D = pd.concat([D.reset_index(drop=True), df_b], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f1c30b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/mv_hvlg946ng63pypv8qzf680000gn/T/ipykernel_30735/3986824649.py:2: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  D.to_excel(\"../data_key/keywords_job_30.xls\", header = True, index= True)\n"
     ]
    }
   ],
   "source": [
    "D = D.T\n",
    "D.to_excel(\"../data_key/keywords_job_30.xls\", header = True, index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc6312b",
   "metadata": {},
   "source": [
    "# Topic finding using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a2a5f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb121ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_list_of_tokens = [[\"a\",\"b\",\"c\"], [\"d\",\"e\",\"f\"]]\n",
    "# [\"a\",\"b\",\"c\"] are the tokens of document 1, [\"d\",\"e\",\"f\"] are the tokens of document 2...\n",
    "content = df['job requirements']\n",
    "list_of_list_of_tokens = []\n",
    "for i in range(len(content)):\n",
    "    a = content[i]\n",
    "    a = a.replace(\",\",\" \")\n",
    "    a = a.replace(\"'\",\"\")\n",
    "    a = a.replace(\"[\",\"\")\n",
    "    a = a.replace(\"]\",\"\")\n",
    "    list_of_list_of_tokens.append(a.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0401cdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_LDA = corpora.Dictionary(list_of_list_of_tokens)\n",
    "dictionary_LDA.filter_extremes(no_below=3)\n",
    "corpus = [dictionary_LDA.doc2bow(list_of_tokens) for list_of_tokens in list_of_list_of_tokens]\n",
    "\n",
    "num_topics = 2 #can change this number of topic\n",
    "lda_model = models.LdaModel(corpus, num_topics=num_topics, \n",
    "                            id2word=dictionary_LDA,                                   \n",
    "                            passes=4, alpha=[0.01]*num_topics,\n",
    "                            eta=[0.01]*len(dictionary_LDA.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "916f3be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.020*\"museum\" + 0.020*\"art\" + 0.010*\"program\" + 0.008*\"position\" + 0.008*\"support\" + 0.007*\"ability\" + 0.007*\"staff\" + 0.007*\"require\" + 0.007*\"community\" + 0.006*\"event\" + 0.006*\"provide\" + 0.006*\"time\" + 0.006*\"employee\" + 0.005*\"director\" + 0.005*\"communication\" + 0.005*\"job\" + 0.005*\"development\" + 0.005*\"opportunity\" + 0.005*\"project\" + 0.004*\"collection\" + 0.004*\"status\" + 0.004*\"department\" + 0.004*\"employment\" + 0.004*\"management\" + 0.004*\"environment\" + 0.004*\"exhibition\" + 0.004*\"application\" + 0.004*\"manage\" + 0.004*\"benefit\" + 0.004*\"report\"\n",
      "\n",
      "1: 0.017*\"art\" + 0.015*\"student\" + 0.015*\"design\" + 0.010*\"ability\" + 0.008*\"school\" + 0.007*\"position\" + 0.007*\"require\" + 0.006*\"time\" + 0.006*\"job\" + 0.006*\"program\" + 0.006*\"project\" + 0.006*\"provide\" + 0.005*\"teach\" + 0.005*\"knowledge\" + 0.005*\"develop\" + 0.005*\"environment\" + 0.005*\"create\" + 0.005*\"education\" + 0.005*\"opportunity\" + 0.005*\"client\" + 0.004*\"community\" + 0.004*\"management\" + 0.004*\"development\" + 0.004*\"employee\" + 0.004*\"college\" + 0.004*\"support\" + 0.004*\"maintain\" + 0.004*\"responsibility\" + 0.004*\"learn\" + 0.004*\"communication\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print topic found:\n",
    "for i,topic in lda_model.show_topics(formatted=True, num_topics=num_topics, num_words=30):\n",
    "    print(str(i)+\": \"+ topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "211e6fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.99875283)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To print the % of topics a document is about, do the following:\n",
    "#(14, 0.9983065953654187)means the first document is 99.8% about topic 14.\n",
    "\n",
    "lda_model[corpus[0]] # corpus[0] means the first document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8defeb13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abfb80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5965f1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5920ec41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae006df1",
   "metadata": {},
   "source": [
    "# Repeat the process for job dataset version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "707d2d52",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/as/Desktop/job data_pre(ver2).csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#sentences = data[\"description\"]\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/as/Desktop/job data_pre(ver2).csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df2\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/as/Desktop/job data_pre(ver2).csv'"
     ]
    }
   ],
   "source": [
    "#sentences = data[\"description\"]\n",
    "df2 = pd.read_csv(\"/Users/as/Desktop/job data_pre(ver2).csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98546e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "content2 = df2['job requirements']\n",
    "sentences2 = []\n",
    "for i in range(len(content2)):\n",
    "    a = content2[i]\n",
    "    a = a.replace(\",\",\" \")\n",
    "    a = a.replace(\"'\",\"\")\n",
    "    a = a.replace(\"[\",\"\")\n",
    "    a = a.replace(\"]\",\"\")\n",
    "    sentences2.append(a)\n",
    "#sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c9aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = TfidfVectorizer(norm = None)\n",
    "X2 = vectorizer2.fit_transform(sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f592cfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X2.shape)\n",
    "word2 = {\"word\":vectorizer2.get_feature_names(), 'tfidf':X2.toarray().sum(axis=0).tolist()}\n",
    "word2 = pd.DataFrame(word2)\n",
    "word2.sort_values(by='tfidf',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e366a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary to store the word/key and tfidf/value\n",
    "dict_of_tokens2 = {i[1]:i[0] for i in vectorizer2.vocabulary_.items()}\n",
    "tfidf_vectors2 = []\n",
    "for row in X2:\n",
    "    tfidf_vectors2.append({dict_of_tokens2[column]:value for (column,value) in zip(row.indices,row.data)})\n",
    "\n",
    "\n",
    "#words for document 0\n",
    "print(tfidf_vectors2[0])\n",
    "#words for document 1\n",
    "print(tfidf_vectors2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880dbc99",
   "metadata": {},
   "source": [
    "# Select the first 10 words as keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf7a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_vectors2 = []\n",
    "for i in range(len(tfidf_vectors2)):\n",
    "    document_i = tfidf_vectors2[i]\n",
    "    if len(document_i.keys()) <= 10:    #保留整个document的words\n",
    "        keyword_vectors2.append(document_i) \n",
    "    else:\n",
    "        a = sorted(document_i.items(), key=lambda document_i: document_i[1], reverse=True)\n",
    "        for j in range(len(a)-1,9,-1):  #从后往前删除\n",
    "            #if a[j][1] != a[9][1]:\n",
    "                a.pop(j)\n",
    "        keyword_vectors2.append(dict(a)) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff2bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#key words for document 0\n",
    "print(keyword_vectors2[0])\n",
    "\n",
    "\n",
    "#key words for document 1\n",
    "print(keyword_vectors2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab361332",
   "metadata": {},
   "outputs": [],
   "source": [
    "D2 = pd.DataFrame(keyword_vectors2[0].keys())\n",
    "\n",
    "\n",
    "for i in range(1,len(keyword_vectors2)):\n",
    "    df_b = pd.DataFrame(keyword_vectors2[i].keys())\n",
    "    D2 = pd.concat([D2.reset_index(drop=True), df_b], axis=1)\n",
    "\n",
    "    \n",
    "D2 = D2.T\n",
    "D2.to_excel(\"keywords job(ver2).xls\", header = True, index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1eb3e1",
   "metadata": {},
   "source": [
    "# Topic finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aae44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_list_of_tokens = [[\"a\",\"b\",\"c\"], [\"d\",\"e\",\"f\"]]\n",
    "# [\"a\",\"b\",\"c\"] are the tokens of document 1, [\"d\",\"e\",\"f\"] are the tokens of document 2...\n",
    "content2 = df2['job requirements']\n",
    "list_of_list_of_tokens2 = []\n",
    "for i in range(len(content2)):\n",
    "    a = content2[i]\n",
    "    a = a.replace(\",\",\" \")\n",
    "    a = a.replace(\"'\",\"\")\n",
    "    a = a.replace(\"[\",\"\")\n",
    "    a = a.replace(\"]\",\"\")\n",
    "    list_of_list_of_tokens2.append(a.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d62991",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_LDA2 = corpora.Dictionary(list_of_list_of_tokens2)\n",
    "dictionary_LDA2.filter_extremes(no_below=3)\n",
    "corpus2 = [dictionary_LDA2.doc2bow(list_of_tokens) for list_of_tokens in list_of_list_of_tokens2]\n",
    "\n",
    "num_topics = 2 #can change this number of topic\n",
    "lda_model2 = models.LdaModel(corpus2, num_topics=num_topics, \n",
    "                            id2word=dictionary_LDA2,                                   \n",
    "                            passes=4, alpha=[0.01]*num_topics,\n",
    "                            eta=[0.01]*len(dictionary_LDA2.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5076bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print topic found:\n",
    "for i,topic in lda_model2.show_topics(formatted=True, num_topics=num_topics, num_words=10):\n",
    "    print(str(i)+\": \"+ topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a236aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To print the % of topics a document is about, do the following:\n",
    "#(14, 0.9983065953654187)means the first document is 99.8% about topic 14.\n",
    "\n",
    "lda_model2[corpus2[0]] # corpus[0] means the first document."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
